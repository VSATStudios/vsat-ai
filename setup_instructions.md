# ğŸš€ VSAT AI - Complete Setup Instructions

## ğŸ“ Project Structure
```
your-project-folder/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.tsx
â”‚   â”œâ”€â”€ main.tsx
â”‚   â””â”€â”€ index.css
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ start_backend.py
â”œâ”€â”€ package.json
â”œâ”€â”€ vite.config.ts
â”œâ”€â”€ tailwind.config.js
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## ğŸ› ï¸ Step-by-Step Setup

### 1. Create Project Folder
```bash
mkdir vsat-ai-project
cd vsat-ai-project
```

### 2. Copy All Files
Copy all the files from this project into your VS Code workspace:
- Frontend files (src/, package.json, config files)
- Backend files (backend/ folder with all Python files)

### 3. Install Frontend Dependencies
```bash
npm install
```

### 4. Setup Backend
```bash
cd backend
python start_backend.py
```

### 5. Start Frontend (in new terminal)
```bash
npm run dev
```

## ğŸ”§ Manual Backend Setup (if needed)

If the automatic setup doesn't work:

```bash
cd backend
pip install -r requirements.txt
python app.py
```

## ğŸ“‹ Prerequisites

### Required Software:
- **Node.js** (v16+): Download from [nodejs.org](https://nodejs.org/)
- **Python** (3.8+): Download from [python.org](https://python.org/)
- **Ollama** (optional): Download from [ollama.ai](https://ollama.ai/)

### For Image Generation:
- **PyTorch**: Automatically installed
- **CUDA** (optional): For GPU acceleration

## ğŸš€ Quick Start Commands

### Terminal 1 (Backend):
```bash
cd backend
python start_backend.py
```

### Terminal 2 (Frontend):
```bash
npm run dev
```

## ğŸŒ Access Your App
- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:5000

## ğŸ” Troubleshooting

### Common Issues:

1. **Port already in use**:
   ```bash
   # Kill processes on ports
   npx kill-port 5173
   npx kill-port 5000
   ```

2. **Python dependencies fail**:
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

3. **Ollama not found**:
   - Install from https://ollama.ai/
   - Run: `ollama serve`
   - Pull a model: `ollama pull llama2`

4. **Image generation fails**:
   - Ensure you have enough RAM (8GB+)
   - Try CPU mode if GPU fails

## ğŸ“± Features

- âœ… **Chat Mode**: AI conversations
- âœ… **Image Generation**: Text-to-image
- âœ… **Real-time Status**: System monitoring
- âœ… **Beautiful UI**: Modern design
- âœ… **Responsive**: Works on all devices

## ğŸ¯ Usage

1. **Chat Mode**: Ask questions, have conversations
2. **Image Mode**: Describe images to generate
3. **Toggle**: Switch between modes anytime
4. **Status**: Monitor AI system health

## ğŸ”§ Development

### File Structure:
- `src/App.tsx`: Main React component
- `backend/app.py`: Flask API server
- `backend/requirements.txt`: Python dependencies
- `package.json`: Node.js dependencies

### Key Technologies:
- **Frontend**: React, TypeScript, Tailwind CSS, Framer Motion
- **Backend**: Flask, PyTorch, Stable Diffusion, Ollama
- **AI**: Ollama (chat), Stable Diffusion (images)

## ğŸ‰ You're Ready!

Your VSAT AI is now ready to use! Enjoy chatting and generating images with your personal AI assistant.

**Developed by Vedant Roy** ğŸ‘¨â€ğŸ’»